{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder typu LSTM Patryk Baryła.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM1QIccFQVTkxk0tyVwRX+R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wranidlo/Autoencoder/blob/master/Autoencoder_typu_LSTM_Patryk_Bary%C5%82a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK40kPEH7MjX",
        "colab_type": "text"
      },
      "source": [
        "Patryk Baryła \n",
        "136216"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd9EHTBD7On4",
        "colab_type": "text"
      },
      "source": [
        "# 1 Budowa Autoencodera LSTM odtwarzającego sekwencje liczb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRK2kZeT8dE9",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Budowa modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndPdsdJt9Ei3",
        "colab_type": "code",
        "outputId": "6a884a33-51f4-4d78-894d-c9b2bc25ef68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM,Dense, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "sequence = np.array([0.111,1.222,0.99,0.444,0.555])\n",
        "seq_len= len(sequence)\n",
        "sequence = sequence.reshape((1, seq_len, 1))\n",
        "\n",
        "number_model = Sequential()\n",
        "number_model.add(LSTM(100, activation='relu', input_shape=(seq_len,1)))\n",
        "number_model.add(RepeatVector(seq_len))\n",
        "number_model.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "number_model.add(TimeDistributed(Dense(1)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18kbj5gn8QVr",
        "colab_type": "text"
      },
      "source": [
        "##1.2 Kompilacja modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJi8ZFmY9E4X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number_model.compile(optimizer='adam', loss='mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qb3NCBfs8gfA",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Zasilenie modelu danymi - trenowanie i testowanie"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ModxX86o7GmM",
        "colab_type": "code",
        "outputId": "cc965d2a-5551-4554-aff5-fa54273ce25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "number_model.fit(sequence, sequence, epochs=300, verbose=0)\n",
        "prediction = number_model.predict(sequence, verbose=0)\n",
        "print(prediction[0,:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.11096953 1.2220011  0.9899885  0.44400543 0.55497974]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDVAcslMLx-z",
        "colab_type": "text"
      },
      "source": [
        "# 2 Autoencoder LSTM dla wiadomości zapisanych w języku naturalnym"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z754CyoL8r9",
        "colab_type": "code",
        "outputId": "094e5533-f666-49b0-ee31-87d609d98f3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "messege = \"this is not real messege it is test messege\"\n",
        "input_data = messege.split()\n",
        "print(\"Zadane wyrażenie : \",input_data)\n",
        "values = array(input_data)\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(\"Wyrażenie jako one-hot : \")\n",
        "print(onehot_encoded)\n",
        "seq_len= len(input_data)\n",
        "one_hot_len = len(onehot_encoded[0])\n",
        "data = np.array(onehot_encoded).reshape((1, seq_len,one_hot_len))\n",
        "\n",
        "model_word = Sequential()\n",
        "model_word.add(LSTM(100, activation='relu', input_shape=(seq_len,one_hot_len)))\n",
        "model_word.add(RepeatVector(seq_len))\n",
        "model_word.add(LSTM(100, activation='relu', return_sequences=True))\n",
        "model_word.add(TimeDistributed(Dense(one_hot_len)))\n",
        "\n",
        "model_word.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "model_word.fit(data, data, epochs=300, verbose=0)\n",
        "\n",
        "pred = model_word.predict(data, verbose=0)\n",
        "print(\"Wyniki\")\n",
        "for e in pred[0]:\n",
        "  print(np.argmax(e), \" - \", label_encoder.inverse_transform([argmax(e)]))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zadane wyrażenie :  ['this', 'is', 'not', 'real', 'messege', 'it', 'is', 'test', 'messege']\n",
            "Wyrażenie jako one-hot : \n",
            "[[0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0.]]\n",
            "Wyniki\n",
            "6  -  ['this']\n",
            "0  -  ['is']\n",
            "3  -  ['not']\n",
            "4  -  ['real']\n",
            "2  -  ['messege']\n",
            "1  -  ['it']\n",
            "0  -  ['is']\n",
            "5  -  ['test']\n",
            "2  -  ['messege']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}